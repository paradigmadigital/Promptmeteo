{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b559000b-5af7-49ed-8e0a-c9c4765167f0",
   "metadata": {},
   "source": [
    "# Promptmteo Usage - Save and Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d34032-bdaa-4317-94ef-432793c2a1dd",
   "metadata": {},
   "source": [
    "## 1. Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404b619-fdbb-4306-be6c-d145c4de1043",
   "metadata": {},
   "source": [
    "### 1.1 Instance a DocumentClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4106fe4b-4ee3-4763-a54a-7dcfe9febc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptmeteo import DocumentClassifier\n",
    "\n",
    "clf = DocumentClassifier(\n",
    "        language            = 'en',\n",
    "        model_provider_name = 'hf_pipeline',\n",
    "        model_name          = 'google/flan-t5-small',\n",
    "        prompt_labels       = ['positive', 'negative']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d8729-635c-4ee9-b59f-d3a9646cf253",
   "metadata": {},
   "source": [
    "### 1.2 Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bed89f-1fea-4d23-a56a-1076990147c4",
   "metadata": {},
   "source": [
    "#### 1.2.1 Predefined prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e533b297-de29-4e55-8404-1d58c424db5f",
   "metadata": {},
   "source": [
    "Promptmeteo has predefined prompt templates for each of the availables languages, models and tasks. This allows the user not to wonder about defining the prefect prompt but rather, to parametrize the prompt with the parameters of the use case. For the document classification task in english with OpenAI, the prompt template is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29a6f79c-95ca-4fe9-a945-6c8379888d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPLATE:\n",
      "    \"I need you to help me with a text classification task.\n",
      "    {__PROMPT_DOMAIN__}\n",
      "    {__PROMPT_LABELS__}\n",
      "\n",
      "    {__CHAIN_THOUGHT__}\n",
      "    {__ANSWER_FORMAT__}\"\n",
      "\n",
      "\n",
      "PROMPT_DOMAIN:\n",
      "    \"The texts you will be processing are from the {__DOMAIN__} domain.\"\n",
      "\n",
      "\n",
      "PROMPT_LABELS:\n",
      "    \"I want you to classify the texts into one of the following categories:\n",
      "    {__LABELS__}.\"\n",
      "\n",
      "\n",
      "PROMPT_DETAIL:\n",
      "    \"\"\n",
      "\n",
      "\n",
      "CHAIN_THOUGHT:\n",
      "    \"Please provide a step-by-step argument for your answer, explain why you\n",
      "    believe your final choice is justified, and make sure to conclude your\n",
      "    explanation with the name of the class you have selected as the correct\n",
      "    one, in lowercase and without punctuation.\"\n",
      "\n",
      "\n",
      "ANSWER_FORMAT:\n",
      "    \"In your response, include only the name of the class as a single word, in\n",
      "    lowercase, without punctuation, and without adding any other statements or\n",
      "    words.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf.task.prompt.PROMPT_EXAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f9379c-fcfe-4736-84be-47ce75196afb",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b81ee-2bac-4e20-9860-9670fddf1b55",
   "metadata": {},
   "source": [
    "#### 1.2.2 Prompt text - Prompt injection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d81af-4601-4366-94f5-09bc9039890b",
   "metadata": {},
   "source": [
    "This template is used to build a prompt text by adding the stament bellow into the template. This technique is called **prompt injection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a89220b2-de0d-48a3-9f80-d624f5d877d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need you to help me with a text classification task.  I want you to classify the texts into one of the following categories: positive, negative.\n",
      "Please provide a step-by-step argument for your answer, explain why you believe your final choice is justified, and make sure to conclude your explanation with the name of the class you have selected as the correct one, in lowercase and without punctuation. In your response, include only the name of the class as a single word, in lowercase, without punctuation, and without adding any other statements or words.\n"
     ]
    }
   ],
   "source": [
    "print(clf.task.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9870f4-f36d-490c-86cc-e7fa7bba1165",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cf474a-1003-477b-8f92-2cc898a3b7b3",
   "metadata": {},
   "source": [
    "#### 1.2.3 Injecting labels - Zero-shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a5bf76-0eb0-442e-9f45-77472a7acb70",
   "metadata": {},
   "source": [
    "We can see tha not only the prompt has beenn build correctly, but also the labels `['positive', 'negative']` from the class inicialitations has been injected. Given the labels without more examples is called **Zero-shot prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00571ba9-d404-4342-bb7d-138823f1216f",
   "metadata": {},
   "source": [
    "I need you to help me with a text classification task.  I want you to classify the texts into one of the following categories: **positive, negative.**\n",
    "Please provide a step-by-step argument for your answer, explain why you believe your final choice is justified, and make sure to conclude your explanation with the name of the class you have selected as the correct one, in lowercase and without punctuation. In your response, include only the name of the class as a single word, in lowercase, without punctuation, and without adding any other statements or words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe750dc3-ba7d-4403-bd1a-68e2e6177718",
   "metadata": {},
   "source": [
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37bca87-fa99-4143-9564-e7ae9364510a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8098ae-bad4-43f3-8c0b-4f7cceab8b6a",
   "metadata": {},
   "source": [
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c362572-35c8-4319-bed5-517484430d76",
   "metadata": {},
   "source": [
    "## 2. Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba3d55-1061-43b7-acfd-13ff8d83370f",
   "metadata": {},
   "source": [
    "### 2.1 Train function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0707a324-78a1-4b58-b318-5f2808eb3620",
   "metadata": {},
   "source": [
    "The model can be trained by giving examples to the function `train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc3141d3-8c0b-4dac-a472-cccd4c3d4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.train(\n",
    "    examples    = ['i am happy', 'doesnt matter', 'I hate it'],\n",
    "    annotations = ['positive', 'neutral', 'negative'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adbbf2a-c7ee-43d3-a445-2a94f53a4301",
   "metadata": {},
   "source": [
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df6a6d-4d38-4e42-a045-22d7e463a224",
   "metadata": {},
   "source": [
    "### 2.2 Examples Injection - Few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1591ccbb-25ab-4610-9f9d-9e4a6313cac2",
   "metadata": {},
   "source": [
    "When a new sample cames, the examples are added to the prompt to help the model to improve the answers. This technique is called **Few-show prompting**. This examples are choosed rom those that are more related to the new sample passes for makein inference. We can see that now, the prompt with the examples has the following aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "092ffb73-2bc8-42db-afb1-ca885c75962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I need you to help me with a text classification task.  I want you to classify the texts into one of the following categories: positive, negative.\n",
      "Please provide a step-by-step argument for your answer, explain why you believe your final choice is justified, and make sure to conclude your explanation with the name of the class you have selected as the correct one, in lowercase and without punctuation. In your response, include only the name of the class as a single word, in lowercase, without punctuation, and without adding any other statements or words.\n",
      "\n",
      "Ejemplo: I hate it\n",
      "Respuesta: negative\n",
      "\n",
      "Ejemplo: doesnt matter\n",
      "Respuesta: neutral\n",
      "\n",
      "Ejemplo: i am happy\n",
      "Respuesta: positive\n",
      "\n",
      "Ejemplo: NEW EXAMPLE\n",
      "Respuesta: \n"
     ]
    }
   ],
   "source": [
    "print(clf.task._get_prompt('NEW EXAMPLE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7f3b4-d40d-4757-91d3-823e2455c706",
   "metadata": {},
   "source": [
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f711ac62-309a-441c-adfb-aa009d0cd334",
   "metadata": {},
   "source": [
    "### 2.3 Save Model - FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d27b6a-3696-44d0-a234-7a36615ce524",
   "metadata": {},
   "source": [
    "The examples given to the function train are saved in a vectorstore in local (with FAISS) and this vectorstore can be serialized to disk. Saving this examples in disk allow us to easily reuse it from new use cases without having to recover the original data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c748ded2-28a3-4e03-a813-f62e454f16c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<promptmeteo.document_classifier.DocumentClassifier at 0x7f185318b190>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.save_model('my_classifier.meteo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a2ae5-8745-4e23-8167-b3d0fea79c61",
   "metadata": {},
   "source": [
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb332b-2a95-4733-b221-03909f059e5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e50993-018e-4fac-93f7-5f4db4fbb369",
   "metadata": {},
   "source": [
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5544d1b-eacf-4deb-a04c-22627123ce98",
   "metadata": {},
   "source": [
    "## 3. Load a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2fe212-4dc9-4303-90c2-3cb670b10195",
   "metadata": {},
   "source": [
    "### 3.1 Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2c604-67c7-4834-8552-d69206762eb1",
   "metadata": {},
   "source": [
    "For reloading a model we have to intanciate a `DocumentClassifier` and use the function `load_model()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cae37b63-2780-4581-8dac-89a1919c0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptmeteo import DocumentClassifier\n",
    "\n",
    "new_clf = DocumentClassifier(\n",
    "        language            = 'en',\n",
    "        model_provider_name = 'hf_pipeline',\n",
    "        model_name          = 'google/flan-t5-small',\n",
    "        prompt_labels       = ['positive', 'negative']\n",
    "    ).load_model('my_classifier.meteo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f27c6-1b71-4299-ad38-fa23230cee30",
   "metadata": {},
   "source": [
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382efddf-7688-46a7-b4ef-2955b3be8cee",
   "metadata": {},
   "source": [
    "### 3.2 Predict new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69571f3e-9e19-4956-bc41-2ae2aff2717e",
   "metadata": {},
   "source": [
    "By calling the function `predict()` we can use the prompt created with the examples loaded again to predict the classification over new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "298b74ce-20a8-44b3-b946-65a7000f35ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['positive']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_clf.predict(['so cool!!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d96c7-601b-4391-9660-85c91a74d6d2",
   "metadata": {},
   "source": [
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cd2c84-23a6-4eba-933d-89725978dc3b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0247bb95-6491-42bf-80a6-762c133b2c41",
   "metadata": {},
   "source": [
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d2939-3941-4714-9f69-082fa391c017",
   "metadata": {},
   "source": [
    "## 4 Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa2277-0785-4143-9a88-d7cd7be528ea",
   "metadata": {},
   "source": [
    "* In this example we have shown how Promptmeteo can be used as a machine learning frameworks such as Scikit-Learn o Pytorch. It has a similar interface with allows to save the results from the training in a binary file and reuse it. This eases the integration of LLM solution in ML pipeline tools such as Sagemaker or Vertex.\n",
    "\n",
    "* Promptmeteo does not only include code data to simplify the integration to LLM model and services. It also include predefined Prompt Engineer logic for different models and tasks. It allows to focus on developing a solution rather than writting prompts, and ensures that the prompt has been tested correctly by Promptmeteo, which make this kind os solution less error-prone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
